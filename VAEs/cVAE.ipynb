{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69be676e-9733-45f1-9b30-9d2c330367ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490141ea-7e42-4c30-8284-e76646a12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794e0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the main device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acefec-7cd1-427d-a81a-1b7f10ece3fe",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43c399e-e1e4-4f3c-b595-4d1863f78543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ec232/venvs/in5310/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAR DATA\n",
    "# Load car data for project 2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import litdata\n",
    "\n",
    "\n",
    "class ToRGBTensor:\n",
    "    \"\"\"Code from Mariuaas copied from Discourse\"\"\"\n",
    "    def __call__(self, img):\n",
    "        return transforms.functional.to_tensor(img).expand(3, -1, -1)  # Expand to 3 channels\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "    \n",
    "    \n",
    "class GetMoiraLabel:\n",
    "    def __call__(self, tensor):\n",
    "        return int(tensor.squeeze()[1])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "\n",
    "def get_data(input_shape: list):\n",
    "    \"\"\"\n",
    "    Get train and test data loader based on educload .tar data\n",
    "    Code adapted from Mariuaas from Discourse\n",
    "    \"\"\"\n",
    "    # Define data path\n",
    "    DATA_PATH = '/projects/ec232/data/'\n",
    "\n",
    "    # Define mean and std from ImageNet data\n",
    "    IN_MEAN = [0.485, 0.456, 0.406]\n",
    "    IN_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Define postprocessing / transform of data modalities\n",
    "    postprocess = (  # Create tuple for image and class...\n",
    "        transforms.Compose([  # Handles processing of the .jpg image\n",
    "            ToRGBTensor(),  # Convert from PIL image to RGB torch.Tensor\n",
    "            transforms.Grayscale(num_output_channels=input_shape[2]),\n",
    "            transforms.Resize(input_shape[:2]),  # Resize images\n",
    "            #transforms.Normalize(IN_MEAN, IN_STD),  # Normalize image to correct mean/std\n",
    "            #transforms.Normalize(0.5, 0.5),\n",
    "            \n",
    "        ]),\n",
    "        transforms.Compose([  # Handles processing of the .jpg image\n",
    "            transforms.ToTensor(), # Convert .scores.npy file to tensor\n",
    "            GetMoiraLabel(),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Load data\n",
    "    data = litdata.LITDataset(\n",
    "        \"CarRecs\",\n",
    "        DATA_PATH,\n",
    "        override_extensions=[\"jpg\", \"scores.npy\"],  # first load image, then scores\n",
    "    ).map_tuple(*postprocess)\n",
    "\n",
    "    return data\n",
    "\n",
    "N_CHANNELS = 1\n",
    "#INPUT_SHAPE = [96, 96, N_CHANNELS]\n",
    "INPUT_SHAPE = [28, 28, N_CHANNELS]\n",
    "# INPUT_SHAPE = [96, 128, N_CHANNELS]\n",
    "batch_size = 64 * 4\n",
    "\n",
    "ORIGINAL = False\n",
    "train_set = get_data(INPUT_SHAPE)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "train_set[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e40ab4-abcb-4155-94d8-441d44d831f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ee353d-2c88-4727-9407-ca7a93219bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3651, 0.3071, 0.3184, 0.3981, 0.2040, 0.2399, 0.1149, 0.0793,\n",
       "          0.0598, 0.3654, 0.0873, 0.1678, 0.2175, 0.1723, 0.1702, 0.2607,\n",
       "          0.1740, 0.1987, 0.1874, 0.3287, 0.4106, 0.4207, 0.3178, 0.2477,\n",
       "          0.2932, 0.3610, 0.3210, 0.4523],\n",
       "         [0.5054, 0.3172, 0.0962, 0.5261, 0.2245, 0.2551, 0.2998, 0.1964,\n",
       "          0.1210, 0.4555, 0.1492, 0.0876, 0.1160, 0.2000, 0.2342, 0.2266,\n",
       "          0.2404, 0.2181, 0.2096, 0.2199, 0.3168, 0.3570, 0.2840, 0.2595,\n",
       "          0.3302, 0.3206, 0.3387, 0.4719],\n",
       "         [0.2687, 0.1913, 0.0896, 0.2180, 0.1852, 0.1343, 0.1326, 0.2753,\n",
       "          0.1499, 0.4075, 0.1960, 0.0670, 0.1821, 0.1625, 0.1911, 0.2454,\n",
       "          0.3370, 0.3321, 0.6601, 0.5612, 0.7381, 0.2864, 0.2713, 0.2132,\n",
       "          0.3560, 0.3108, 0.3477, 0.5785],\n",
       "         [0.1596, 0.1020, 0.0882, 0.1386, 0.0821, 0.1292, 0.3641, 0.1508,\n",
       "          0.1683, 0.1964, 0.1600, 0.3470, 0.2151, 0.2673, 0.2825, 0.2765,\n",
       "          0.2368, 0.1451, 0.1500, 0.6034, 0.5861, 0.1804, 0.1800, 0.1780,\n",
       "          0.1725, 0.4584, 0.5385, 0.5021],\n",
       "         [0.2109, 0.1274, 0.0950, 0.3657, 0.5544, 0.3445, 0.7547, 0.4216,\n",
       "          0.1192, 0.0911, 0.0567, 0.1376, 0.1310, 0.1933, 0.1891, 0.2730,\n",
       "          0.0590, 0.1857, 0.1583, 0.0927, 0.1179, 0.1199, 0.1196, 0.3429,\n",
       "          0.1782, 0.4325, 0.5366, 0.3844],\n",
       "         [0.1722, 0.0583, 0.0374, 0.0574, 0.1537, 0.5524, 0.4273, 0.4145,\n",
       "          0.1779, 0.1225, 0.1714, 0.0981, 0.0913, 0.1222, 0.0934, 0.1052,\n",
       "          0.0574, 0.0579, 0.0864, 0.1060, 0.0451, 0.1338, 0.1228, 0.4570,\n",
       "          0.1318, 0.0933, 0.1575, 0.1495],\n",
       "         [0.2637, 0.1151, 0.0369, 0.1887, 0.4138, 0.4146, 0.4117, 0.4094,\n",
       "          0.3515, 0.1651, 0.0901, 0.0914, 0.0787, 0.4272, 0.4162, 0.5445,\n",
       "          0.6049, 0.3826, 0.0928, 0.0872, 0.0376, 0.1747, 0.1926, 0.5677,\n",
       "          0.1749, 0.2192, 0.2952, 0.1412],\n",
       "         [0.3801, 0.2006, 0.0442, 0.1024, 0.2243, 0.3155, 0.3859, 0.4086,\n",
       "          0.4030, 0.4738, 0.1844, 0.0355, 0.4611, 0.5967, 0.0708, 0.1304,\n",
       "          0.3385, 0.0663, 0.0552, 0.2969, 0.6388, 0.3081, 0.3237, 0.3128,\n",
       "          0.1116, 0.0890, 0.1267, 0.3247],\n",
       "         [0.4300, 0.2479, 0.1144, 0.1210, 0.2088, 0.2454, 0.2964, 0.3597,\n",
       "          0.4262, 0.5274, 0.2487, 0.2339, 0.5267, 0.4097, 0.0636, 0.1252,\n",
       "          0.1936, 0.2223, 0.0502, 0.3125, 0.3354, 0.4559, 0.4869, 0.4868,\n",
       "          0.3145, 0.1291, 0.0760, 0.3154],\n",
       "         [0.3385, 0.1840, 0.1002, 0.1517, 0.0578, 0.2032, 0.3470, 0.3556,\n",
       "          0.2621, 0.2749, 0.2090, 0.0624, 0.1681, 0.2378, 0.3122, 0.2263,\n",
       "          0.2435, 0.3474, 0.1314, 0.3138, 0.2286, 0.3488, 0.3613, 0.3068,\n",
       "          0.1008, 0.2435, 0.0690, 0.3112],\n",
       "         [0.2586, 0.1710, 0.0787, 0.1324, 0.2269, 0.1616, 0.3432, 0.4139,\n",
       "          0.4624, 0.6533, 0.7222, 0.6679, 0.4538, 0.1726, 0.0931, 0.1513,\n",
       "          0.1411, 0.1285, 0.1088, 0.7752, 0.1875, 0.2902, 0.3856, 0.5271,\n",
       "          0.2462, 0.4889, 0.0569, 0.1631],\n",
       "         [0.0627, 0.0664, 0.0846, 0.0979, 0.1618, 0.2165, 0.7932, 0.8606,\n",
       "          0.8688, 0.9057, 0.8871, 0.8743, 0.8540, 0.8290, 0.8274, 0.6784,\n",
       "          0.1078, 0.0935, 0.0751, 0.5313, 0.1647, 0.2158, 0.7976, 0.7465,\n",
       "          0.0817, 0.1571, 0.0598, 0.1664],\n",
       "         [0.4314, 0.1923, 0.1803, 0.1950, 0.8325, 0.9359, 0.9537, 0.9699,\n",
       "          0.9688, 0.9509, 0.9277, 0.9039, 0.8926, 0.8747, 0.8581, 0.8581,\n",
       "          0.8444, 0.7993, 0.5045, 0.6819, 0.5712, 0.5784, 0.7293, 0.5893,\n",
       "          0.1165, 0.0919, 0.1370, 0.1370],\n",
       "         [0.3825, 0.3362, 0.4424, 0.9210, 0.9913, 0.9927, 0.9950, 0.9987,\n",
       "          0.9880, 0.9637, 0.9392, 0.9167, 0.9019, 0.8840, 0.8774, 0.8475,\n",
       "          0.8387, 0.8525, 0.8379, 0.8117, 0.7788, 0.6383, 0.6008, 0.4977,\n",
       "          0.0819, 0.0908, 0.1636, 0.1169],\n",
       "         [0.2958, 0.3425, 0.9165, 0.9774, 0.9974, 0.9999, 0.9999, 0.9981,\n",
       "          0.9806, 0.9657, 0.9413, 0.9299, 0.8971, 0.8814, 0.8504, 0.8545,\n",
       "          0.8326, 0.8023, 0.7870, 0.7293, 0.6609, 0.6144, 0.5314, 0.4314,\n",
       "          0.0864, 0.0939, 0.1417, 0.3838],\n",
       "         [0.2596, 0.2929, 0.4773, 0.9814, 0.9929, 0.9974, 0.9974, 0.9886,\n",
       "          0.9700, 0.9515, 0.9327, 0.9119, 0.8798, 0.8588, 0.8505, 0.8421,\n",
       "          0.8166, 0.7533, 0.6786, 0.6389, 0.6086, 0.5754, 0.4890, 0.5720,\n",
       "          0.0931, 0.0946, 0.1096, 0.2824],\n",
       "         [0.3098, 0.3144, 0.2025, 0.0854, 0.7307, 0.9874, 0.9756, 0.9916,\n",
       "          0.9788, 0.9449, 0.9172, 0.8740, 0.8865, 0.8481, 0.8405, 0.8319,\n",
       "          0.7091, 0.6599, 0.6155, 0.5759, 0.5608, 0.5221, 0.5954, 0.2720,\n",
       "          0.1515, 0.1036, 0.0684, 0.2631],\n",
       "         [0.2780, 0.7564, 0.7217, 0.1312, 0.4345, 0.0813, 0.4769, 0.8274,\n",
       "          0.9361, 0.9214, 0.8496, 0.8825, 0.8365, 0.7801, 0.8364, 0.6216,\n",
       "          0.0452, 0.1727, 0.5507, 0.5385, 0.6134, 0.5351, 0.3959, 0.1317,\n",
       "          0.2567, 0.2295, 0.1054, 0.2546],\n",
       "         [0.3090, 0.6741, 0.9160, 0.8627, 0.1214, 0.1016, 0.1931, 0.1147,\n",
       "          0.6319, 0.0916, 0.1962, 0.6274, 0.7240, 0.7012, 0.7710, 0.0857,\n",
       "          0.0924, 0.0239, 0.5435, 0.6380, 0.4910, 0.5012, 0.0998, 0.0691,\n",
       "          0.2185, 0.3976, 0.2432, 0.3242],\n",
       "         [0.3159, 0.3904, 0.8350, 0.9700, 0.9618, 0.5480, 0.1959, 0.1378,\n",
       "          0.7478, 0.1058, 0.1491, 0.1588, 0.6326, 0.7219, 0.3908, 0.0956,\n",
       "          0.2538, 0.0568, 0.5818, 0.4888, 0.5618, 0.0840, 0.3219, 0.1821,\n",
       "          0.1296, 0.2923, 0.2841, 0.3416],\n",
       "         [0.3595, 0.3856, 0.7485, 0.7347, 0.9412, 0.9424, 0.9454, 0.8286,\n",
       "          0.8831, 0.4363, 0.2981, 0.3465, 0.5757, 0.7372, 0.0745, 0.1540,\n",
       "          0.1801, 0.0567, 0.4235, 0.5410, 0.0673, 0.3438, 0.3728, 0.3873,\n",
       "          0.2754, 0.3632, 0.3458, 0.3441],\n",
       "         [0.3961, 0.4076, 0.4850, 0.7261, 0.7032, 0.6878, 0.8718, 0.9019,\n",
       "          0.9055, 0.8847, 0.8654, 0.8607, 0.6098, 0.6351, 0.0871, 0.3169,\n",
       "          0.2746, 0.1484, 0.3891, 0.1491, 0.3551, 0.3320, 0.3495, 0.4019,\n",
       "          0.3931, 0.4257, 0.3947, 0.3598],\n",
       "         [0.2480, 0.2138, 0.4536, 0.2001, 0.4293, 0.7156, 0.6663, 0.6414,\n",
       "          0.4943, 0.4729, 0.4381, 0.3414, 0.4424, 0.3740, 0.0594, 0.2413,\n",
       "          0.2049, 0.2106, 0.2186, 0.3541, 0.3938, 0.4529, 0.4625, 0.4347,\n",
       "          0.3996, 0.3871, 0.3804, 0.3526],\n",
       "         [0.2541, 0.4241, 0.4511, 0.2586, 0.3365, 0.0824, 0.2319, 0.5930,\n",
       "          0.7039, 0.7760, 0.7867, 0.7257, 0.5025, 0.0968, 0.0897, 0.3199,\n",
       "          0.8239, 0.2500, 0.3410, 0.4420, 0.4917, 0.4717, 0.4636, 0.3975,\n",
       "          0.4006, 0.3755, 0.3715, 0.3328],\n",
       "         [0.2199, 0.4582, 0.5137, 0.5115, 0.0968, 0.5081, 0.3617, 0.0415,\n",
       "          0.4872, 0.4985, 0.4850, 0.4295, 0.3582, 0.0668, 0.0794, 0.1386,\n",
       "          0.3257, 0.3145, 0.4357, 0.4945, 0.4619, 0.4537, 0.4244, 0.3908,\n",
       "          0.3762, 0.3682, 0.3561, 0.3299],\n",
       "         [0.3011, 0.4409, 0.5102, 0.4737, 0.5592, 0.0875, 0.0711, 0.2378,\n",
       "          0.7027, 0.6667, 0.5465, 0.5565, 0.4888, 0.0586, 0.0874, 0.2622,\n",
       "          0.1958, 0.4667, 0.4813, 0.4569, 0.4569, 0.3958, 0.4061, 0.3841,\n",
       "          0.3418, 0.3446, 0.3393, 0.3278],\n",
       "         [0.4020, 0.4218, 0.4606, 0.4817, 0.5419, 0.4894, 0.2197, 0.0738,\n",
       "          0.0747, 0.0808, 0.0840, 0.0680, 0.0588, 0.0589, 0.0567, 0.1027,\n",
       "          0.4656, 0.4447, 0.4490, 0.4094, 0.4094, 0.3986, 0.3743, 0.3608,\n",
       "          0.3681, 0.3457, 0.3278, 0.3126],\n",
       "         [0.3890, 0.4170, 0.4485, 0.4795, 0.4606, 0.4789, 0.4794, 0.4530,\n",
       "          0.2205, 0.0815, 0.0931, 0.1040, 0.2169, 0.1576, 0.2992, 0.4386,\n",
       "          0.4634, 0.4277, 0.4006, 0.4100, 0.3738, 0.3564, 0.3507, 0.3539,\n",
       "          0.3307, 0.3110, 0.3029, 0.2877]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898ad3aa-952f-4945-9f2a-5e9c7e124391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# MNIST DATA\\n# Choose the path where you will/have already saved the MNIST dataset\\ndata_dir = '/fp/projects01/ec232/data'\\n\\n# Get dataset\\nORIGINAL = True\\nbatch_size = 64 * 4\\nINPUT_SHAPE = [28, 28, 1]\\nN_CHANNELS = 1\\ntransform = transforms.ToTensor()\\ntrain_set = MNIST(root=data_dir, train=True, download=True, transform=transform)\\nN = len(train_set)\\n\\n# Create data loader\\ntrain_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\\ntrain_set[0][0].size()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r\"\"\"\n",
    "# MNIST DATA\n",
    "# Choose the path where you will/have already saved the MNIST dataset\n",
    "data_dir = '/fp/projects01/ec232/data'\n",
    "\n",
    "# Get dataset\n",
    "ORIGINAL = True\n",
    "batch_size = 64 * 4\n",
    "INPUT_SHAPE = [28, 28, 1]\n",
    "N_CHANNELS = 1\n",
    "transform = transforms.ToTensor()\n",
    "train_set = MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "N = len(train_set)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "train_set[0][0].size()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18312b-70b6-47cc-9d85-2c2221a45d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff9b0ad-f1d1-433d-bb05-2ac9be72e554",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4445f380-bb12-4074-835f-2fb6c425a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize_gaussian(mean, std):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        mean : [torch.tensor] Mean vector. Shape: batch_size x z_dim.\n",
    "        std  : [torch.tensor] Standard deviation vection. Shape: batch_size x z_dim.\n",
    "    \n",
    "    Output:\n",
    "        z    : [torch.tensor] z sampled from the Normal distribution with mean and standard deviation given by the inputs. \n",
    "                              Shape: batch_size x z_dim.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample epsilon from N(0,I)\n",
    "    eps = torch.randn_like(std)\n",
    "\n",
    "    # Calculate z using reparameterization trick\n",
    "    z = mean + std*eps\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "101f191e-7cc3-440f-b081-fb7595dfdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vae_loss(x, x_hat, mean, logvar):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x       : [torch.tensor] Original sample\n",
    "        x_hat   : [torch.tensor] Reproduced sample\n",
    "        mean    : [torch.tensor] Mean mu of the variational posterior given sample x\n",
    "        logvar  : [torch.tensor] log of the variance sigma^2 of the variational posterior given sample x\n",
    "    \"\"\"\n",
    "\n",
    "    # Recontruction loss\n",
    "    reconstruction_loss = ((x - x_hat)**2).sum()\n",
    "    #print(\"RL\", reconstruction_loss)\n",
    "    \n",
    "    # KL divergence\n",
    "    KL_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    #print(\"KL\", KL_divergence)\n",
    "    \n",
    "    # Get the total loss\n",
    "    kl_weight = 1\n",
    "    loss = reconstruction_loss + KL_divergence * kl_weight\n",
    "\n",
    "    return loss / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8820201d-d232-462c-aab9-b23927c8cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.resblock = nn.Sequential(nn.Conv2d(in_channels, out_channels,\n",
    "                                                kernel_size=3, padding=1, bias=False),\n",
    "                                      nn.ReLU(True),\n",
    "                                      nn.Conv2d(out_channels, out_channels,\n",
    "                                                kernel_size=1, bias=False))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return input + self.resblock(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280e232-deba-422e-b76a-e8d9705b4d0b",
   "metadata": {},
   "source": [
    "# cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6b957db-cf91-492a-822c-dfa1c2392e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEncoder(nn.Module):\n",
    "    \"\"\" Convolutional encoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        feature_dim = 32 * 23 * 31\n",
    "        if ORIGINAL: feature_dim = 32 * 6 * 6  # TODO HOW DO I ARRIVE AT THESE NUMBERS?\n",
    "        self.conv1 = nn.Conv2d(n_channels + 1, 64, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, stride=2)\n",
    "        self.mean_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.logvar_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.cls_token_fc = nn.Linear(feature_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = torch.flatten(x)\n",
    "        #print(\"forward encoder:\", x.size())\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.size())  # [64, 32, 23, 31]  # [64, 32, 6, 6]\n",
    "        x = x.flatten(1)\n",
    "        \n",
    "        # TODO also try out other priors\n",
    "        mean = self.mean_fc(x)\n",
    "        logvar = self.logvar_fc(x)\n",
    "        cls_token = self.cls_token_fc(x)\n",
    "\n",
    "        return mean, logvar, cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a14368b-90ab-4164-8b98-6fdcc92f876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDecoder(nn.Module):\n",
    "    \"\"\" Convolutional decoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        feature_dim = 32 * 23 * 31\n",
    "        if ORIGINAL: feature_dim = 32 * 6 * 6\n",
    "        self.fc = nn.Linear(z_dim + n_classes, feature_dim)\n",
    "        self.conv2 = nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv1 = nn.ConvTranspose2d(64, n_channels, kernel_size=3, stride=2, output_padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # print(\"dec z.size()\", z.size())\n",
    "        x = F.relu(self.fc(z))\n",
    "        if ORIGINAL: x = x.view(-1, 32, 6, 6) \n",
    "        else: x = x.view(-1, 32, 23, 31)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16aee1-2f2c-48fb-9ffe-09da117acc0e",
   "metadata": {},
   "source": [
    "## Extended cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8bf0b4-e150-415e-b5d1-77c23a04f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEncoder(nn.Module):\n",
    "    \"\"\" Convolutional encoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels, hidden_dims=None):\n",
    "        super().__init__()\n",
    "\n",
    "        in_channels = n_channels + 1\n",
    "                \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "            #hidden_dims = [32, 128, 512]\n",
    "\n",
    "        modules = []\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size=3, stride=2, padding=1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        \n",
    "        feature_dim = 512 * 3 * 3\n",
    "        if ORIGINAL: feature_dim = 512 * 1 * 1\n",
    "        self.mean_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.logvar_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.cls_token_fc = nn.Linear(feature_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        #print(\"!!! feature_dim:\", x.size())  # [64, 32, 23, 31]  # [64, 32, 6, 6]\n",
    "        x = x.flatten(1)\n",
    "        \n",
    "        # TODO also try out other priors\n",
    "        mean = self.mean_fc(x)\n",
    "        logvar = self.logvar_fc(x)\n",
    "        cls_token = self.cls_token_fc(x)\n",
    "\n",
    "        return mean, logvar, cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "341f986c-602f-45bb-ac52-35d6dd83decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDecoder(nn.Module):\n",
    "    \"\"\" Convolutional decoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels, hidden_dims=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        feature_dim = 512 * 3 * 3\n",
    "        if ORIGINAL: feature_dim = 512 * 1 * 1\n",
    "        self.fc = nn.Linear(z_dim + n_classes, feature_dim)\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "            #hidden_dims = [32, 128, 512]\n",
    "        hidden_dims.reverse()\n",
    "        \n",
    "        padding_last_layer = 1\n",
    "        if ORIGINAL: padding_last_layer = 3\n",
    "        modules = []\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "        self.decoder = nn.Sequential(*modules)       \n",
    "        \n",
    "        self.final_layer = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                       hidden_dims[-1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.ConvTranspose2d(hidden_dims[-1], \n",
    "                              out_channels=n_channels,\n",
    "                              kernel_size=3, \n",
    "                              padding=padding_last_layer),\n",
    "                    nn.Tanh())\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        if ORIGINAL:  x = x.view(-1, 512, 1, 1)\n",
    "        else: x = x.view(-1, 512, 3, 3)\n",
    "        x = self.decoder(x)\n",
    "        # print(\"after decoder:\", x.size())\n",
    "        x = self.final_layer(x)\n",
    "        # print(\"after final_layer:\", x.size())\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c279a2-4bbe-4036-a79f-8e1bef78f4eb",
   "metadata": {},
   "source": [
    "## Declare cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0689a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    \"\"\" Conditional Variational Auto-Encoder class. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels=1, img_size=[28,28]):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.encoder = CEncoder(z_dim, n_classes, n_channels)\n",
    "        self.decoder = CDecoder(z_dim, n_classes, n_channels)\n",
    "\n",
    "        # Add learnable class token\n",
    "        self.cls_param = nn.Parameter(torch.zeros(n_classes, *img_size))\n",
    "\n",
    "    def get_cls_emb(self, c):\n",
    "        return self.cls_param[c].unsqueeze(1)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x   : [torch.Tensor] Image input of shape [batch_size, n_channels, *img_size]\n",
    "            c   : [torch.Tensor] Class labels for x of shape [batch_size], where the class in indicated by a\n",
    "        \"\"\"\n",
    "\n",
    "        # Get cls embedding\n",
    "        cls_emb = self.get_cls_emb(c)\n",
    "\n",
    "        # Concatenate cls embedding to the input\n",
    "        #print(\"x.size() =\", x.size())\n",
    "        #print(\"cls_emb.size() =\", cls_emb.size())\n",
    "        x = torch.cat((x, cls_emb), dim=1)\n",
    "\n",
    "        # Get the mean, logvar, and cls token from the encoder\n",
    "        mean, logvar, cls_token = self.encoder(x)\n",
    "\n",
    "        # Calculate the standard deviation. Note: in log-space, squareroot is divide by two\n",
    "        std = torch.exp(logvar / 2)\n",
    "\n",
    "        # Sample the latent using the reparameterization trick\n",
    "        z = reparameterize_gaussian(mean, std)\n",
    "        # print(\"######\")\n",
    "        # print(\"z.size() =\", z.size())\n",
    "        \n",
    "        # Concatenate cls token to z\n",
    "        z = torch.cat((z, F.softmax(cls_token, dim=1)), dim=1)\n",
    "        \n",
    "        # Get reconstructed x from the decoder\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        return x, x_hat, mean, logvar, cls_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187b3b5-7dcb-4cec-badf-05eb02b80725",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a71bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]: 100%|██████████| 24/24 [00:30<00:00,  1.28s/it, loss=47]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 1222.9691718969095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]: 100%|██████████| 24/24 [00:28<00:00,  1.18s/it, loss=42.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 1072.555681640382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]: 100%|██████████| 24/24 [00:28<00:00,  1.18s/it, loss=36.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 938.4434882530477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]: 100%|██████████| 24/24 [00:27<00:00,  1.17s/it, loss=31.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 813.2457742348446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=26.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 693.0646948994836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=22]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 580.869300053904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=19]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 484.04609878694674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=16]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 413.4567038637054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]: 100%|██████████| 24/24 [00:29<00:00,  1.25s/it, loss=14]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 365.32087103787177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/25]: 100%|██████████| 24/24 [00:30<00:00,  1.27s/it, loss=13.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 332.4026621742606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/25]: 100%|██████████| 24/24 [00:28<00:00,  1.21s/it, loss=12.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 307.70969168403616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=11.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 289.4662256795896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/25]: 100%|██████████| 24/24 [00:28<00:00,  1.18s/it, loss=11.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 274.9684812203715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=10.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 263.0594315975489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/25]: 100%|██████████| 24/24 [00:28<00:00,  1.19s/it, loss=10.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 252.6300822784542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=10.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 245.40508824691642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/25]: 100%|██████████| 24/24 [00:40<00:00,  1.69s/it, loss=9.7] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 237.18552539377873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/25]: 100%|██████████| 24/24 [00:42<00:00,  1.77s/it, loss=9.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 230.4366478736213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/25]: 100%|██████████| 24/24 [00:32<00:00,  1.34s/it, loss=9.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 225.44998035836034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=9.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 220.42621355216085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=9.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 215.94090359307094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=8.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 211.90746022030777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/25]: 100%|██████████| 24/24 [00:30<00:00,  1.25s/it, loss=8.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 208.00913135047136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=8.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 205.00064350243858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/25]: 100%|██████████| 24/24 [00:28<00:00,  1.20s/it, loss=8.24]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 201.80623518564138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the VAE\n",
    "z_dim = 128\n",
    "conditioned_model = CVAE(z_dim, n_classes=10, n_channels=N_CHANNELS, img_size=INPUT_SHAPE[:2]).to(device)\n",
    "\n",
    "# Feel free to tweak the training parameters\n",
    "epochs = 25\n",
    "lr = 0.00001\n",
    "optimizer = Adam(conditioned_model.parameters(), lr=lr)\n",
    "\n",
    "# Train for a few epochs\n",
    "conditioned_model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "# TODO USE: with traindata.shufflecontext(): 2 # do training loop ...\n",
    "for epoch in range(epochs):\n",
    "    train_bar = tqdm(iterable=train_loader)\n",
    "    total_loss = 0\n",
    "    for i, (x, c) in enumerate(train_bar):\n",
    "        x = x.to(device)\n",
    "        c = c.to(device)\n",
    "        # Get x_hat, mean, logvar,and cls_token from the conditioned_model\n",
    "        x, x_hat, mean, logvar, cls_token = conditioned_model.forward(x, c)\n",
    "        x = x[:, :N_CHANNELS, :, :] # excluding cls_emebdding\n",
    "\n",
    "        # Get vae loss\n",
    "        #print(\"x.size() =\", x.size())\n",
    "        #print(\"x_hat.size() =\", x_hat.size())        \n",
    "        vae_loss = get_vae_loss(x, x_hat, mean, logvar)\n",
    "\n",
    "        # Get cross entropy loss for the cls token\n",
    "        # print(\"cls_token.size() =\", cls_token.size())\n",
    "        # print(\"OHE\", F.one_hot(c, num_classes=10).double().size())\n",
    "        cls_loss = F.cross_entropy(cls_token, F.one_hot(c, num_classes=10).double(), reduction='sum')\n",
    "\n",
    "        # Add the losses as a weighted sum. NB: We weight the cls_loss by 10 here, but feel free to tweak it.\n",
    "        loss = vae_loss + cls_loss  #* 10 # reducing vae_loss instead\n",
    "        total_loss += loss / len(x)\n",
    "        \n",
    "        # Update model parameters based on loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_bar.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        train_bar.set_postfix(loss = loss.item() / len(x))\n",
    "    losses.append(total_loss.item())\n",
    "    print(\"Total loss:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38472171-f983-4254-8634-85a71cb3ae95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x151cbb6b2500>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print convergence plot\n",
    "plt.plot(losses, \"-bo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28500ec4-ead5-4023-a326-5aace7c79f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model in evalulation mode\n",
    "conditioned_model.eval()\n",
    "\n",
    "# Select a class label\n",
    "cls_label = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample noise from N(0,I)\n",
    "    # TODO also try out other priors\n",
    "    z = torch.randn(1, z_dim).to(device)\n",
    "\n",
    "    # Make a one-hot for the selected class label, which will act as the cls token\n",
    "    cls_token = F.one_hot(torch.tensor(cls_label).unsqueeze(0), num_classes=10).to(device)\n",
    "\n",
    "    # Concatenate z and the cls token\n",
    "    z = torch.cat((z, cls_token), dim=1)  # TODO prob this should be saved acc to instructions!\n",
    "\n",
    "    # Generate new image with the decoder\n",
    "    x_hat = conditioned_model.decoder(z)\n",
    "    x_hat = x_hat.squeeze(0).cpu().detach()\n",
    "\n",
    "# Show generated image\n",
    "plt.figure(figsize=(5,5))\n",
    "x_hat_permuted = x_hat.permute(1, 2 ,0)\n",
    "#plt.imshow((x_hat_permuted+1)*.5, cmap=plt.get_cmap('gray'))\n",
    "plt.imshow(x_hat_permuted, cmap=plt.get_cmap('gray'))\n",
    "plt.title(f\"A generated image of class={cls_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa2879e4-7e25-4011-a7f8-ee864644b5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]: 100%|██████████| 24/24 [00:30<00:00,  1.26s/it, loss=7.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 192.46822849247005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=7.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 185.56736832457995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=7.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 183.09136972908996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]: 100%|██████████| 24/24 [00:29<00:00,  1.25s/it, loss=7.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 181.0191375224053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=7.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 179.7202076530084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]: 100%|██████████| 24/24 [00:29<00:00,  1.25s/it, loss=7.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 178.04122784632324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]: 100%|██████████| 24/24 [00:31<00:00,  1.29s/it, loss=7.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 176.92295691008414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=7.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 175.912993389714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=7.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 174.9484075319654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=7.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 173.66905414213292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=7.23]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 172.90099945950456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=7.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 172.05062670367104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/25]: 100%|██████████| 24/24 [00:30<00:00,  1.29s/it, loss=7.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 171.49617884106868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=7.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 170.46800978729567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/25]: 100%|██████████| 24/24 [00:30<00:00,  1.27s/it, loss=7.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 169.93628848114582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=7.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 169.24930181873165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=6.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 168.38182117038272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/25]: 100%|██████████| 24/24 [00:30<00:00,  1.26s/it, loss=6.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 167.49054485928667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=6.86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 167.1767656081356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=7.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 166.42218654947024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/25]: 100%|██████████| 24/24 [00:30<00:00,  1.25s/it, loss=7.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 165.91543338417873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=6.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 165.28124077619785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/25]: 100%|██████████| 24/24 [00:28<00:00,  1.21s/it, loss=6.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 164.84071435365226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=6.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 164.1474874230667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/25]: 100%|██████████| 24/24 [00:28<00:00,  1.21s/it, loss=7.06]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 163.65281386437294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_bar = tqdm(iterable=train_loader)\n",
    "    total_loss = 0\n",
    "    for i, (x, c) in enumerate(train_bar):\n",
    "        x = x.to(device)\n",
    "        c = c.to(device)\n",
    "        # Get x_hat, mean, logvar,and cls_token from the conditioned_model\n",
    "        x, x_hat, mean, logvar, cls_token = conditioned_model.forward(x, c)\n",
    "        x = x[:, :N_CHANNELS, :, :] # excluding cls_emebdding\n",
    "\n",
    "        # Get vae loss\n",
    "        #print(\"x.size() =\", x.size())\n",
    "        #print(\"x_hat.size() =\", x_hat.size())        \n",
    "        vae_loss = get_vae_loss(x, x_hat, mean, logvar)\n",
    "\n",
    "        # Get cross entropy loss for the cls token\n",
    "        # print(\"cls_token.size() =\", cls_token.size())\n",
    "        # print(\"OHE\", F.one_hot(c, num_classes=10).double().size())\n",
    "        cls_loss = F.cross_entropy(cls_token, F.one_hot(c, num_classes=10).double(), reduction='sum')\n",
    "\n",
    "        # Add the losses as a weighted sum. NB: We weight the cls_loss by 10 here, but feel free to tweak it.\n",
    "        loss = vae_loss + cls_loss  #* 10 # reducing vae_loss instead\n",
    "        total_loss += loss / len(x)\n",
    "        \n",
    "        # Update model parameters based on loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_bar.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        train_bar.set_postfix(loss = loss.item() / len(x))\n",
    "    losses.append(total_loss.item())\n",
    "    print(\"Total loss:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c4240ae-d6d9-4a28-a966-c5852a601adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x151c744f98d0>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print convergence plot\n",
    "plt.plot(losses, \"-bo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91512ee2-5b5e-489d-9970-608910eef429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This doesn't work\n",
    "# x.size() = torch.Size([64, 4, 96, 128])\n",
    "# x_hat.size() = torch.Size([64, 3, 96, 128])\n",
    "#x - x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efee4a0",
   "metadata": {},
   "source": [
    "To generate new images conditioned on a class label, we sample some noise $z \\sim N(0,I)$ and concatenate the one-hot vector of the class label we want to condition on. Then we use the decoder to generate a new image.\n",
    "If your CVAE model was trained correctly, the cell below should generate new images of the selected class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc90c8-3e4b-488c-b5e9-f0c1b66a0e4f",
   "metadata": {},
   "source": [
    "## Get generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcf3103e-7204-41a7-8f87-de09e1e7ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model in evalulation mode\n",
    "conditioned_model.eval()\n",
    "\n",
    "# Select a class label\n",
    "cls_label = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample noise from N(0,I)\n",
    "    # TODO also try out other priors\n",
    "    z = torch.randn(1, z_dim).to(device)\n",
    "\n",
    "    # Make a one-hot for the selected class label, which will act as the cls token\n",
    "    cls_token = F.one_hot(torch.tensor(cls_label).unsqueeze(0), num_classes=10).to(device)\n",
    "\n",
    "    # Concatenate z and the cls token\n",
    "    z = torch.cat((z, cls_token), dim=1)  # TODO prob this should be saved acc to instructions!\n",
    "\n",
    "    # Generate new image with the decoder\n",
    "    x_hat = conditioned_model.decoder(z)\n",
    "    x_hat = x_hat.squeeze(0).cpu().detach()\n",
    "\n",
    "# Show generated image\n",
    "plt.figure(figsize=(5,5))\n",
    "x_hat_permuted = x_hat.permute(1, 2 ,0)\n",
    "#plt.imshow((x_hat_permuted+1)*.5, cmap=plt.get_cmap('gray'))\n",
    "plt.imshow(x_hat_permuted, cmap=plt.get_cmap('gray'))\n",
    "plt.title(f\"A generated image of class={cls_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52ee98dc-f294-4414-9f3c-55c540067ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference score: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Preference score:\", train_set[i][1])\n",
    "plt.imshow(train_set[i][0].permute(1,2,0), cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8c3187-18e2-48d0-ab72-c68c64253de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=6.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 162.90423343769675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]: 100%|██████████| 24/24 [00:28<00:00,  1.19s/it, loss=6.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 162.05517538312623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=6.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 161.4320316199945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=6.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 160.61530260572076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=6.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 160.49818857168844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]: 100%|██████████| 24/24 [00:27<00:00,  1.16s/it, loss=6.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 159.21597929302203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=6.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 158.49298781063408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=6.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 157.9914374976818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=6.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 157.07247172091488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=6.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 156.39774194547707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=6.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 155.34073091477953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=6.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 154.3880054475823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/25]: 100%|██████████| 24/24 [00:28<00:00,  1.21s/it, loss=6.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 153.30838108634012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=6.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 151.93667271727463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/25]: 100%|██████████| 24/24 [00:29<00:00,  1.21s/it, loss=6.55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 151.02098990620496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/25]: 100%|██████████| 24/24 [00:29<00:00,  1.23s/it, loss=6]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 149.17499533520564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/25]: 100%|██████████| 24/24 [00:29<00:00,  1.22s/it, loss=6.4] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 148.06150480099936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=6.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 146.48587377006646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/25]: 100%|██████████| 24/24 [00:30<00:00,  1.27s/it, loss=5.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 144.69974981340056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/25]: 100%|██████████| 24/24 [00:28<00:00,  1.20s/it, loss=5.88]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 143.18677429563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/25]: 100%|██████████| 24/24 [00:29<00:00,  1.24s/it, loss=5.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 141.49274543869979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/25]: 100%|██████████| 24/24 [00:28<00:00,  1.19s/it, loss=6.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 140.35394918289134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/25]: 100%|██████████| 24/24 [00:28<00:00,  1.21s/it, loss=5.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 138.4656057018879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/25]:  92%|█████████▏| 22/24 [00:40<00:04,  2.30s/it, loss=5.65]"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_bar = tqdm(iterable=train_loader)\n",
    "    total_loss = 0\n",
    "    for i, (x, c) in enumerate(train_bar):\n",
    "        x = x.to(device)\n",
    "        c = c.to(device)\n",
    "        # Get x_hat, mean, logvar,and cls_token from the conditioned_model\n",
    "        x, x_hat, mean, logvar, cls_token = conditioned_model.forward(x, c)\n",
    "        x = x[:, :N_CHANNELS, :, :] # excluding cls_emebdding\n",
    "\n",
    "        # Get vae loss\n",
    "        #print(\"x.size() =\", x.size())\n",
    "        #print(\"x_hat.size() =\", x_hat.size())        \n",
    "        vae_loss = get_vae_loss(x, x_hat, mean, logvar)\n",
    "\n",
    "        # Get cross entropy loss for the cls token\n",
    "        # print(\"cls_token.size() =\", cls_token.size())\n",
    "        # print(\"OHE\", F.one_hot(c, num_classes=10).double().size())\n",
    "        cls_loss = F.cross_entropy(cls_token, F.one_hot(c, num_classes=10).double(), reduction='sum')\n",
    "\n",
    "        # Add the losses as a weighted sum. NB: We weight the cls_loss by 10 here, but feel free to tweak it.\n",
    "        loss = vae_loss + cls_loss  #* 10 # reducing vae_loss instead\n",
    "        total_loss += loss / len(x)\n",
    "        \n",
    "        # Update model parameters based on loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_bar.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        train_bar.set_postfix(loss = loss.item() / len(x))\n",
    "    losses.append(total_loss.item())\n",
    "    print(\"Total loss:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb81793-f4f1-4ea8-92ab-bf29467a753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print convergence plot\n",
    "plt.plot(losses, \"-bo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa13d1f-5fbe-46e5-883a-7e92f1b2c7b7",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beb12426-cc72-4222-8698-204cabb661e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: stop"
     ]
    }
   ],
   "source": [
    "raise Exception(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af525249-efcf-4cfb-94ca-8e161a56b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(train_set)):\n",
    "    scores.append(train_set[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406c9c3-75a4-4d6a-9df4-b9548cb0e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cca8f-f1aa-45db-9dbd-266c72c3dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score = 9: [562, 2984, 3392, 4864]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9f04a-6dbf-4c13-9874-c4c097332e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37be981-7415-46a9-a6d1-2efd7a047bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preference score:\", train_set[i][1])\n",
    "permuted_train_set = train_set[i][0].permute(1,2,0)\n",
    "\n",
    "plt.imshow((permuted_train_set+1)*.5, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "#i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef2a17-72c7-45ba-9c80-4b19e1a8bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set[0][0]+1)*256/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in5310",
   "language": "python",
   "name": "in5310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
