{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69be676e-9733-45f1-9b30-9d2c330367ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conditional VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490141ea-7e42-4c30-8284-e76646a12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794e0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the main device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acefec-7cd1-427d-a81a-1b7f10ece3fe",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f43c399e-e1e4-4f3c-b595-4d1863f78543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAR DATA\n",
    "# Load car data for project 2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import litdata\n",
    "\n",
    "\n",
    "class ToRGBTensor:\n",
    "    \"\"\"Code from Mariuaas copied from Discourse\"\"\"\n",
    "    def __call__(self, img):\n",
    "        return transforms.functional.to_tensor(img).expand(3, -1, -1)  # Expand to 3 channels\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "    \n",
    "    \n",
    "class GetMoiraLabel:\n",
    "    def __call__(self, tensor):\n",
    "        return int(tensor.squeeze()[1])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "\n",
    "def get_data(input_shape: list):\n",
    "    \"\"\"\n",
    "    Get train and test data loader based on educload .tar data\n",
    "    Code adapted from Mariuaas from Discourse\n",
    "    \"\"\"\n",
    "    # Define data path\n",
    "    DATA_PATH = '/projects/ec232/data/'\n",
    "\n",
    "    # Define mean and std from ImageNet data\n",
    "    IN_MEAN = [0.485, 0.456, 0.406]\n",
    "    IN_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Define postprocessing / transform of data modalities\n",
    "    postprocess = (  # Create tuple for image and class...\n",
    "        transforms.Compose([  # Handles processing of the .jpg image\n",
    "            ToRGBTensor(),  # Convert from PIL image to RGB torch.Tensor\n",
    "            transforms.Grayscale(num_output_channels=input_shape[2]),\n",
    "            transforms.Resize(input_shape[:2]),  # Resize images\n",
    "            #transforms.Normalize(IN_MEAN, IN_STD),  # Normalize image to correct mean/std\n",
    "            #transforms.Normalize(0.5, 0.5),\n",
    "            \n",
    "        ]),\n",
    "        transforms.Compose([  # Handles processing of the .jpg image\n",
    "            transforms.ToTensor(), # Convert .scores.npy file to tensor\n",
    "            GetMoiraLabel(),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Load data\n",
    "    data = litdata.LITDataset(\n",
    "        \"CarRecs\",\n",
    "        DATA_PATH,\n",
    "        override_extensions=[\"jpg\", \"scores.npy\"],  # first load image, then scores\n",
    "    ).map_tuple(*postprocess)\n",
    "\n",
    "    return data\n",
    "\n",
    "N_CHANNELS = 1\n",
    "#INPUT_SHAPE = [96, 96, N_CHANNELS]\n",
    "INPUT_SHAPE = [28, 28, N_CHANNELS]\n",
    "# INPUT_SHAPE = [96, 128, N_CHANNELS]\n",
    "batch_size = 64 * 4\n",
    "\n",
    "ORIGINAL = False\n",
    "train_set = get_data(INPUT_SHAPE)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "train_set[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89e40ab4-abcb-4155-94d8-441d44d831f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "25ee353d-2c88-4727-9407-ca7a93219bda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "898ad3aa-952f-4945-9f2a-5e9c7e124391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST DATA\n",
    "# Choose the path where you will/have already saved the MNIST dataset\n",
    "data_dir = '/fp/projects01/ec232/data'\n",
    "\n",
    "# Get dataset\n",
    "ORIGINAL = True\n",
    "batch_size = 64 * 4\n",
    "INPUT_SHAPE = [28, 28, 1]\n",
    "N_CHANNELS = 1\n",
    "transform = transforms.ToTensor()\n",
    "train_set = MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "N = len(train_set)\n",
    "\n",
    "# Create data loader\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "train_set[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18312b-70b6-47cc-9d85-2c2221a45d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff9b0ad-f1d1-433d-bb05-2ac9be72e554",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4445f380-bb12-4074-835f-2fb6c425a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize_gaussian(mean, std):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        mean : [torch.tensor] Mean vector. Shape: batch_size x z_dim.\n",
    "        std  : [torch.tensor] Standard deviation vection. Shape: batch_size x z_dim.\n",
    "    \n",
    "    Output:\n",
    "        z    : [torch.tensor] z sampled from the Normal distribution with mean and standard deviation given by the inputs. \n",
    "                              Shape: batch_size x z_dim.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample epsilon from N(0,I)\n",
    "    eps = torch.randn_like(std)\n",
    "\n",
    "    # Calculate z using reparameterization trick\n",
    "    z = mean + std*eps\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101f191e-7cc3-440f-b081-fb7595dfdf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vae_loss(x, x_hat, mean, logvar):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        x       : [torch.tensor] Original sample\n",
    "        x_hat   : [torch.tensor] Reproduced sample\n",
    "        mean    : [torch.tensor] Mean mu of the variational posterior given sample x\n",
    "        logvar  : [torch.tensor] log of the variance sigma^2 of the variational posterior given sample x\n",
    "    \"\"\"\n",
    "\n",
    "    # Recontruction loss\n",
    "    reconstruction_loss = ((x - x_hat)**2).sum()\n",
    "    #print(\"RL\", reconstruction_loss)\n",
    "    \n",
    "    # KL divergence\n",
    "    KL_divergence = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    #print(\"KL\", KL_divergence)\n",
    "    \n",
    "    # Get the total loss\n",
    "    kl_weight = 1\n",
    "    loss = reconstruction_loss + KL_divergence * kl_weight\n",
    "\n",
    "    return loss / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8820201d-d232-462c-aab9-b23927c8cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        super(ResidualLayer, self).__init__()\n",
    "        self.resblock = nn.Sequential(nn.Conv2d(in_channels, out_channels,\n",
    "                                                kernel_size=3, padding=1, bias=False),\n",
    "                                      nn.ReLU(True),\n",
    "                                      nn.Conv2d(out_channels, out_channels,\n",
    "                                                kernel_size=1, bias=False))\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return input + self.resblock(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280e232-deba-422e-b76a-e8d9705b4d0b",
   "metadata": {},
   "source": [
    "# cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6b957db-cf91-492a-822c-dfa1c2392e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEncoder(nn.Module):\n",
    "    \"\"\" Convolutional encoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        feature_dim = 32 * 23 * 31\n",
    "        if ORIGINAL: feature_dim = 32 * 6 * 6  # TODO HOW DO I ARRIVE AT THESE NUMBERS?\n",
    "        self.conv1 = nn.Conv2d(n_channels + 1, 64, kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, stride=2)\n",
    "        self.mean_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.logvar_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.cls_token_fc = nn.Linear(feature_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = torch.flatten(x)\n",
    "        #print(\"forward encoder:\", x.size())\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.size())  # [64, 32, 23, 31]  # [64, 32, 6, 6]\n",
    "        x = x.flatten(1)\n",
    "        \n",
    "        # TODO also try out other priors\n",
    "        mean = self.mean_fc(x)\n",
    "        logvar = self.logvar_fc(x)\n",
    "        cls_token = self.cls_token_fc(x)\n",
    "\n",
    "        return mean, logvar, cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a14368b-90ab-4164-8b98-6fdcc92f876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDecoder(nn.Module):\n",
    "    \"\"\" Convolutional decoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        feature_dim = 32 * 23 * 31\n",
    "        if ORIGINAL: feature_dim = 32 * 6 * 6\n",
    "        self.fc = nn.Linear(z_dim + n_classes, feature_dim)\n",
    "        self.conv2 = nn.ConvTranspose2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.conv1 = nn.ConvTranspose2d(64, n_channels, kernel_size=3, stride=2, output_padding=1)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # print(\"dec z.size()\", z.size())\n",
    "        x = F.relu(self.fc(z))\n",
    "        if ORIGINAL: x = x.view(-1, 32, 6, 6) \n",
    "        else: x = x.view(-1, 32, 23, 31)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16aee1-2f2c-48fb-9ffe-09da117acc0e",
   "metadata": {},
   "source": [
    "## Extended cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c8bf0b4-e150-415e-b5d1-77c23a04f646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CEncoder(nn.Module):\n",
    "    \"\"\" Convolutional encoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels, hidden_dims=None):\n",
    "        super().__init__()\n",
    "\n",
    "        in_channels = n_channels + 1\n",
    "                \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "            #hidden_dims = [32, 128, 512]\n",
    "\n",
    "        modules = []\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size=3, stride=2, padding=1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        \n",
    "        feature_dim = 512 * 3 * 3\n",
    "        if ORIGINAL: feature_dim = 512 * 1 * 1\n",
    "        self.mean_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.logvar_fc = nn.Linear(feature_dim, z_dim)\n",
    "        self.cls_token_fc = nn.Linear(feature_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        #print(\"!!! feature_dim:\", x.size())  # [64, 32, 23, 31]  # [64, 32, 6, 6]\n",
    "        x = x.flatten(1)\n",
    "        \n",
    "        # TODO also try out other priors\n",
    "        mean = self.mean_fc(x)\n",
    "        logvar = self.logvar_fc(x)\n",
    "        cls_token = self.cls_token_fc(x)\n",
    "\n",
    "        return mean, logvar, cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "341f986c-602f-45bb-ac52-35d6dd83decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDecoder(nn.Module):\n",
    "    \"\"\" Convolutional decoder for the CVAE. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels, hidden_dims=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        feature_dim = 512 * 3 * 3\n",
    "        if ORIGINAL: feature_dim = 512 * 1 * 1\n",
    "        self.fc = nn.Linear(z_dim + n_classes, feature_dim)\n",
    "        \n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "            #hidden_dims = [32, 128, 512]\n",
    "        hidden_dims.reverse()\n",
    "        \n",
    "        padding_last_layer = 1\n",
    "        if ORIGINAL: padding_last_layer = 3\n",
    "        modules = []\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "        self.decoder = nn.Sequential(*modules)       \n",
    "        \n",
    "        self.final_layer = nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                       hidden_dims[-1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                    nn.LeakyReLU(),\n",
    "                    nn.ConvTranspose2d(hidden_dims[-1], \n",
    "                              out_channels=n_channels,\n",
    "                              kernel_size=3, \n",
    "                              padding=padding_last_layer),\n",
    "                    nn.Tanh())\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        if ORIGINAL:  x = x.view(-1, 512, 1, 1)\n",
    "        else: x = x.view(-1, 512, 3, 3)\n",
    "        x = self.decoder(x)\n",
    "        # print(\"after decoder:\", x.size())\n",
    "        x = self.final_layer(x)\n",
    "        # print(\"after final_layer:\", x.size())\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c279a2-4bbe-4036-a79f-8e1bef78f4eb",
   "metadata": {},
   "source": [
    "## Declare cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0689a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    \"\"\" Conditional Variational Auto-Encoder class. \"\"\"\n",
    "\n",
    "    def __init__(self, z_dim, n_classes, n_channels=1, img_size=[28,28]):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.n_classes = n_classes\n",
    "        self.n_channels = n_channels\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.encoder = CEncoder(z_dim, n_classes, n_channels)\n",
    "        self.decoder = CDecoder(z_dim, n_classes, n_channels)\n",
    "\n",
    "        # Add learnable class token\n",
    "        self.cls_param = nn.Parameter(torch.zeros(n_classes, *img_size))\n",
    "\n",
    "    def get_cls_emb(self, c):\n",
    "        return self.cls_param[c].unsqueeze(1)\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x   : [torch.Tensor] Image input of shape [batch_size, n_channels, *img_size]\n",
    "            c   : [torch.Tensor] Class labels for x of shape [batch_size], where the class in indicated by a\n",
    "        \"\"\"\n",
    "\n",
    "        # Get cls embedding\n",
    "        cls_emb = self.get_cls_emb(c)\n",
    "\n",
    "        # Concatenate cls embedding to the input\n",
    "        #print(\"x.size() =\", x.size())\n",
    "        #print(\"cls_emb.size() =\", cls_emb.size())\n",
    "        x = torch.cat((x, cls_emb), dim=1)\n",
    "\n",
    "        # Get the mean, logvar, and cls token from the encoder\n",
    "        mean, logvar, cls_token = self.encoder(x)\n",
    "\n",
    "        # Calculate the standard deviation. Note: in log-space, squareroot is divide by two\n",
    "        std = torch.exp(logvar / 2)\n",
    "\n",
    "        # Sample the latent using the reparameterization trick\n",
    "        z = reparameterize_gaussian(mean, std)\n",
    "        # print(\"######\")\n",
    "        # print(\"z.size() =\", z.size())\n",
    "        \n",
    "        # Concatenate cls token to z\n",
    "        z = torch.cat((z, F.softmax(cls_token, dim=1)), dim=1)\n",
    "        \n",
    "        # Get reconstructed x from the decoder\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        return x, x_hat, mean, logvar, cls_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187b3b5-7dcb-4cec-badf-05eb02b80725",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68a71bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]: 100%|██████████| 24/24 [00:23<00:00,  1.00it/s, loss=30.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 722.8829916780815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, loss=28.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 680.079500053211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, loss=25.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 632.5784946904917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=21.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 567.6566204883026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it, loss=18.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 484.789930820332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it, loss=14.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 396.40340279807737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, loss=12.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 319.7018732940778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, loss=11.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 276.0450616915311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, loss=10.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 255.26597501999433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=10.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 242.1750602811974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=9.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 232.53389100657245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=9.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 224.23956043875245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 217.74838012716333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=9.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 212.7707343991247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 207.46637141554882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 203.74152185890958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 199.8839218844327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 196.97103194486616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 194.04251712277932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=8.13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 191.06769202716117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=7.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 188.7993001922566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/25]: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it, loss=7.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 186.72732474352233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/25]: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it, loss=7.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 184.94273370215004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/25]: 100%|██████████| 24/24 [00:24<00:00,  1.01s/it, loss=7.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 183.104915134642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/25]: 100%|██████████| 24/24 [00:24<00:00,  1.02s/it, loss=7.72]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 181.44516321890322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the VAE\n",
    "z_dim = 128\n",
    "conditioned_model = CVAE(z_dim, n_classes=10, n_channels=N_CHANNELS, img_size=INPUT_SHAPE[:2]).to(device)\n",
    "\n",
    "# Feel free to tweak the training parameters\n",
    "epochs = 25\n",
    "lr = 0.00001\n",
    "optimizer = Adam(conditioned_model.parameters(), lr=lr)\n",
    "\n",
    "# Train for a few epochs\n",
    "conditioned_model.train()\n",
    "\n",
    "losses = []\n",
    "\n",
    "# TODO USE: with traindata.shufflecontext(): 2 # do training loop ...\n",
    "for epoch in range(epochs):\n",
    "    train_bar = tqdm(iterable=train_loader)\n",
    "    total_loss = 0\n",
    "    for i, (x, c) in enumerate(train_bar):\n",
    "        x = x.to(device)\n",
    "        c = c.to(device)\n",
    "        # Get x_hat, mean, logvar,and cls_token from the conditioned_model\n",
    "        x, x_hat, mean, logvar, cls_token = conditioned_model.forward(x, c)\n",
    "        x = x[:, :N_CHANNELS, :, :] # excluding cls_emebdding\n",
    "\n",
    "        # Get vae loss\n",
    "        #print(\"x.size() =\", x.size())\n",
    "        #print(\"x_hat.size() =\", x_hat.size())        \n",
    "        vae_loss = get_vae_loss(x, x_hat, mean, logvar)\n",
    "\n",
    "        # Get cross entropy loss for the cls token\n",
    "        # print(\"cls_token.size() =\", cls_token.size())\n",
    "        # print(\"OHE\", F.one_hot(c, num_classes=10).double().size())\n",
    "        cls_loss = F.cross_entropy(cls_token, F.one_hot(c, num_classes=10).double(), reduction='sum')\n",
    "\n",
    "        # Add the losses as a weighted sum. NB: We weight the cls_loss by 10 here, but feel free to tweak it.\n",
    "        loss = vae_loss + cls_loss  #* 10 # reducing vae_loss instead\n",
    "        total_loss += loss / len(x)\n",
    "        \n",
    "        # Update model parameters based on loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_bar.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "        train_bar.set_postfix(loss = loss.item() / len(x))\n",
    "    losses.append(total_loss.item())\n",
    "    print(\"Total loss:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c4240ae-d6d9-4a28-a966-c5852a601adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14ba809713f0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print convergence plot\n",
    "plt.plot(losses, \"-bo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91512ee2-5b5e-489d-9970-608910eef429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This doesn't work\n",
    "# x.size() = torch.Size([64, 4, 96, 128])\n",
    "# x_hat.size() = torch.Size([64, 3, 96, 128])\n",
    "#x - x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efee4a0",
   "metadata": {},
   "source": [
    "To generate new images conditioned on a class label, we sample some noise $z \\sim N(0,I)$ and concatenate the one-hot vector of the class label we want to condition on. Then we use the decoder to generate a new image.\n",
    "If your CVAE model was trained correctly, the cell below should generate new images of the selected class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc90c8-3e4b-488c-b5e9-f0c1b66a0e4f",
   "metadata": {},
   "source": [
    "## Get generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dcf3103e-7204-41a7-8f87-de09e1e7ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model in evalulation mode\n",
    "conditioned_model.eval()\n",
    "\n",
    "# Select a class label\n",
    "cls_label = 2\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Sample noise from N(0,I)\n",
    "    # TODO also try out other priors\n",
    "    z = torch.randn(1, z_dim).to(device)\n",
    "\n",
    "    # Make a one-hot for the selected class label, which will act as the cls token\n",
    "    cls_token = F.one_hot(torch.tensor(cls_label).unsqueeze(0), num_classes=10).to(device)\n",
    "\n",
    "    # Concatenate z and the cls token\n",
    "    z = torch.cat((z, cls_token), dim=1)  # TODO prob this should be saved acc to instructions!\n",
    "\n",
    "    # Generate new image with the decoder\n",
    "    x_hat = conditioned_model.decoder(z)\n",
    "    x_hat = x_hat.squeeze(0).cpu().detach()\n",
    "\n",
    "# Show generated image\n",
    "plt.figure(figsize=(5,5))\n",
    "x_hat_permuted = x_hat.permute(1, 2 ,0)\n",
    "#plt.imshow((x_hat_permuted+1)*.5, cmap=plt.get_cmap('gray'))\n",
    "plt.imshow(x_hat_permuted, cmap=plt.get_cmap('gray'))\n",
    "plt.title(f\"A generated image of class={cls_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "52ee98dc-f294-4414-9f3c-55c540067ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference score: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVX0lEQVR4nO3dbWyUZboH8P8FCIVSSilvFQly6gsCatc0cKLkBKNHXBKVJcasJupJzMEPq3GTNTlGP6yJfjDm7OpqyCbs0ciaPW42WQ1+MOviWwwxIgXLiyDCqQUppSzyjlChXOdDxz1V+/yvOs90Zs7e/19CWubqPXPPM3N1pnM993Wbu0NE/vGNqPQERKQ8lOwiiVCyiyRCyS6SCCW7SCJGlfPGRo8e7TU1NZlxM6PjWeWgtraWjo2uu7e3l8aZUaP4YWT3eSjjo4oJi0f3OxLN7fz58zQ+YoReT8qpp6cHx44dG/RBz5XsZnYzgN8AGAngv9z9KfbzNTU1WLhwYWY8emKcPXs2M7ZgwQI6dsyYMTTe0dFB4319fZmxqVOn0rGXXXYZjTc2NhZ921F85MiRdGz0y2Dy5Mk0furUKRqPfgkz0dyiXzRM9As0zwtPJT344IOZsaJ/7ZrZSAArAfwYwFwAd5rZ3GKvT0SGV573WAsA7Hb3Dnf/GsAfAdxWmmmJSKnlSfYZAL4Y8P99hcu+xcxWmFmbmbWxt+EiMryG/dMTd1/l7q3u3nrBBRcM982JSIY8yd4FYOaA/19UuExEqlCeZN8A4FIzm21mowH8FMDrpZmWiJRa0aU3dz9nZg8AeBP9pbcX3f2TYAzOnDmTGY/e5tfV1WXGjhw5QsfOnDmTxqN6Mithff3113Ts9u3baZzdLwA4d+4cjef5LGTSpEk0vmHDBhpfsmQJjbPzF6JjXskafbWW1vLIVWd39zcAvFGiuYjIMNLpTSKJULKLJELJLpIIJbtIIpTsIolQsoskoqzr2ceMGYPm5ubM+NGjR+n4cePGZcbGjh1Lx3722Wc0fujQIRpnSzWjenC0nj1awrpz504ab2hoyIxNmDCBjt26dSuNRzX+aPyUKVMyY9OnT6djo/MX2PMBAL766qvM2HCfup2nj8Bw1fj1yi6SCCW7SCKU7CKJULKLJELJLpIIJbtIIspaeuvt7UVnZ2dmPOpkypbH7t27t+ixANDd3U3jLS0tmbHTp0/Tsaz8BAAHDhyg8aj8xUqW0fLXqOQYlaj27NlD47t27cqMLV68mI7dsmULjc+aNavo8UuXLqVjo/s9nEtgVXoTkVyU7CKJULKLJELJLpIIJbtIIpTsIolQsoskoqx1dnenrYWjWvjo0aMzY4cPH6Zje3p6aDzaiZXVspuamujYaKfTL774gsbHjx9P46yOv3//fjo2cuLECRqfPXs2jbe3t2fGohr/559/TuPHjh2jcXb+w5o1a+jYqEV2nt1pI3nq7GysXtlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRZa2zjxw5EhMnTsyMR+u2WbvoqK3wjBkzaLyxsZHGWY0/aoE9ZswYGmctjwG+XTTA6/hRm+vo/IKoTr927VoaZ+dV7Nu3j46N6s1RnwC2jTebFxCfG1FfX0/j0XOZPS7R433+/PnMGGthnSvZzawTwAkAfQDOuXtrnusTkeFTilf2692dnwolIhWnv9lFEpE32R3AX81so5mtGOwHzGyFmbWZWVu0nY+IDJ+8b+MXuXuXmU0FsNbMPnX39wf+gLuvArAKAOrr64evS5+IULle2d29q/D1IIDXACwoxaREpPSKTnYzqzWzum++B3ATgG2lmpiIlFaet/HTALxWqOuNAvDf7v4XNqCxsRF33313ZpzVDwHg+PHjmTHWjx6I683R+Kjumse1115L49Ga8pMnT2bGovXm0Vr5mTNn0nie7aqjenK07XHU272uri4zFtXJ169fT+PReR2LFi2icXZcoi282fkHLFZ0srt7B4Crix0vIuWl0ptIIpTsIolQsoskQskukgglu0giyrrE9cyZM9i5c2dmfNq0aXR8c3NzZmzevHl0bFTGiZZTsjJRVDKMtnSOylfvvPMOjX/wwQeZsaiME8WjLZ+j8hm771H5atQo/vSMSm9sOXU0Nnouzpkzh8bXrVtH42wL8KgcyqiVtIgo2UVSoWQXSYSSXSQRSnaRRCjZRRKhZBdJRFnr7GZGa6effvopHc/q0RMmTKBjWSvo6Lqj8VGtOarpRnXVL7/8ksZZy+SoVh21CovOT4iwNtpRu+VoWXF039iWztFj0tHRQeNXX80XfEbPt02bNmXGovbebBtstnW5XtlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRZa2znzt3jtaMGxoa6HhWV43WlEfbIkfY9UdbNkdti59++mkaX7CA771RW1ubGYvaUEf15uj8g6gWztaUR+cnsPsF9PdHYKI6PhM9ny688EIaj7aEZsd19+7ddCzLIXaf9coukgglu0gilOwiiVCyiyRCyS6SCCW7SCKU7CKJKGudHeB9raO11WxstJ49qgfn6Y/+zDPP0LHXXXcdjd9+++00/vLLL9M4q5VHfeHZevOhiNa7Hzp0KDMW9WaPat3ROQAsHvXyj2r8bE05EM+dWbJkCY2z5zKr0Yev7Gb2opkdNLNtAy6bZGZrzWxX4Ss/G0ZEKm4ob+NfAnDzdy57BMDb7n4pgLcL/xeRKhYmu7u/D+C7vW5uA7C68P1qAMtKOy0RKbViP6Cb5u7dhe8PAMj848vMVphZm5m1RX8nicjwyf1pvPd/apb5yZm7r3L3VndvHTt2bN6bE5EiFZvsPWbWBACFrwdLNyURGQ7FJvvrAO4tfH8vgDWlmY6IDJewzm5mrwBYDGCyme0D8EsATwH4k5ndB2APgDuGcmO9vb20H/cll1xCx7Ne3KxHOBD3GI/6fLN69HPPPUfHPvzwwzTOeogD8ZpztoY5Ov8guu5oXXaefe+jz3CiubHrBnidParxR2vht2/fTuNdXV00XlNTkxm79dZb6djGxsbMGHseh8nu7ndmhG6IxopI9dDpsiKJULKLJELJLpIIJbtIIpTsIoko6xLX3t5edHZ2Zsbr6uroeNYWedy4cXRs1HY4amvMSnvr16+nY2+55RYaj0pIUfmLtcmOxkbHJRofLQ1m1x8tA42WPEflMVZ6i5bHRnOL2ofPmjWLxltaWjJju3btomNZ6U2tpEVEyS6SCiW7SCKU7CKJULKLJELJLpIIJbtIIspaZ58yZQruv//+zHi0VS1r7xvVyaMlrtES2bfeeiszFm0HvXfvXhqPatlRPZnd92gJanTcovHRMlR2/kN025Ho/AS2BXi0lXV0zsfGjRtp/Prrr6fxw4e/29bx/+zcuZOOZedtsPMD9Moukgglu0gilOwiiVCyiyRCyS6SCCW7SCKU7CKJKGudvba2FgsXLsyMR3VXVrM9efIkHRttTRzV2W+88cbMWLTTzcqVK2k8Wrcd1bpZPM+2xkMR1brZltHRYxLV8C+++GIaZ2vKo3l/+OGHNL58+XIajx6zO+7I7r7+5JNP0rHsMaPPBXqtIvIPQ8kukgglu0gilOwiiVCyiyRCyS6SCCW7SCLKWmcH+Nrs5uZmOnb//v2ZsahPd7TmvL6+nsbvueeezNjzzz9Px0a92aN4tJ00E/U/v+iii2g86o8e1cLZuvDLL7+cjo3WnEe1blaHj87LWLduXa54tCU0ey7PnTuXjmX7FLD7Fb6ym9mLZnbQzLYNuOxxM+sys/bCv6XR9YhIZQ3lbfxLAG4e5PJn3L2l8O+N0k5LREotTHZ3fx9Adg8dEfl/Ic8HdA+Y2ZbC2/zMZl9mtsLM2sys7ciRIzluTkTyKDbZfwugGUALgG4Av8r6QXdf5e6t7t7KGgCKyPAqKtndvcfd+9z9PIDfAVhQ2mmJSKkVlexm1jTgvz8BsC3rZ0WkOoR1djN7BcBiAJPNbB+AXwJYbGYtABxAJ4DsZvADuDtdR1xTU0PHX3XVVZmx48eP07FR7/WXXnqJxl999dXMWNRjPFo7HfW0j2rlTNQj4NChQzR++vRpGo/mzo57T08PHfvQQw/RePR8mTp1amZswoQJdGzUyz/aQz3qcTBv3rzMWHROyObNmzNj7JyNMNnd/c5BLn4hGici1UWny4okQskukgglu0gilOwiiVCyiySirEtczYyWgqKWyqy8xrZzBuISUWTfvn1Fj508eTKNd3d303hUemOthc+ePUvHslbPQNzuOWpFzcqOUTn0iSeeoPE8Wz5PnDiRxqP71dTUROPz58+ncbY0OCr7sWXJbDm0XtlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRZa2zuzutpUctk9nyvaieHLVEjpbIslp3VAePbruxsZHGo+2kWS07mlvUxjo6rlGtmy0zjURbMkePGVueu2fPHjo2Wj47e/ZsGo/OX2Atn6Nlx1deeWVmjM1br+wiiVCyiyRCyS6SCCW7SCKU7CKJULKLJELJLpKIsm/ZzETr2VkdPmp5HMWjGj9r75unnTIQ14vzrNuO7le0bjtvnN336PyDKB7dNjvHIHrMoudiS0sLjUdbWbN41HqcrcVnzxW9soskQskukgglu0gilOwiiVCyiyRCyS6SCCW7SCLKWmfv6+uja7PHjx9Px7O66okTJ+jYU6dO0XhUF2U9zJ999lk6NqoXHzhwgMajNemsthqtq45q+NFxier4rJ7d0NBAx0bnJ0TbLkfjmWgb7mhb5egcANaPP3o+TJo0KTPGjnf4ym5mM83sXTPbbmafmNlDhcsnmdlaM9tV+MofORGpqKG8jT8H4BfuPhfAPwP4mZnNBfAIgLfd/VIAbxf+LyJVKkx2d+92902F708A2AFgBoDbAKwu/NhqAMuGaY4iUgI/6AM6M7sYwI8ArAcwzd2/2aTsAIBpGWNWmFmbmbVFvdREZPgMOdnNbDyAPwP4ubt/a+WG95+5P+jZ++6+yt1b3b21vr4+12RFpHhDSnYzuwD9if4Hd3+1cHGPmTUV4k0ADg7PFEWkFMLSm5kZgBcA7HD3Xw8IvQ7gXgBPFb6uGcJ10dJAtD0wWwoaLVmMlrhGLZMfe+yxzFj/ISr+uqPxETY+Kq1Ft513iWse0WO2Y8cOGm9ubs6MRWW/qMX2DTfcQONvvvkmjXd2dmbGonInKyOzUutQ6uzXAbgbwFYzay9c9ij6k/xPZnYfgD0A7hjCdYlIhYTJ7u7rAGT9+ue/3kSkauh0WZFEKNlFEqFkF0mEkl0kEUp2kUSUdYnriBEjMG7cuMx4tE0uq7tGNfpoKWZHRweNT58+PTN28CA/n2j58uU0/tFHH9F4tIUvaz2ct84etTWOxrNlplEdvampicajds6sVh4t/Y3iUR29t7eXxt99993M2Jw5c+jY6DHJold2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJRFnr7GZGa+nROl62BviKK66gY6+55hoaj+rRrLYZtRVub2+n8cjYsWNpPGo9zETnNkQ13WhrY7bePTpu0fkF0WPG6vjRbUddlTZv3kzj0XkfrMdBV1cXHct6N7DzHvTKLpIIJbtIIpTsIolQsoskQskukgglu0gilOwiiShrnd3d6Trfjz/+mI5/7733MmMrV66kY6N6cLT9L6ttzp8/n46NtpOO1k5HWw+zra6j7Z7zbGsMxMc1un0mqvFHPetZzTlabx7dL9aXAQBuuukmGr/rrrsyY3l7EGTRK7tIIpTsIolQsoskQskukgglu0gilOwiiVCyiyRiKPuzzwTwewDTADiAVe7+GzN7HMC/A/hb4Ucfdfc32HX19fXh6NGjmfGo1r1s2bLMWFQ3jdYXRzVdVvuM1uFHc8uzlj6K562jR3vLR3OP7jsT1dGj22bq6upoPFrPnrfHAHuuR+ddsPMq2PN8KCfVnAPwC3ffZGZ1ADaa2dpC7Bl3/88hXIeIVNhQ9mfvBtBd+P6Eme0AMGO4JyYipfWD/mY3s4sB/AjA+sJFD5jZFjN70cwaMsasMLM2M2s7duxYvtmKSNGGnOxmNh7AnwH83N2PA/gtgGYALeh/5f/VYOPcfZW7t7p7a/R3kIgMnyElu5ldgP5E/4O7vwoA7t7j7n3ufh7A7wAsGL5pikheYbJb/xKbFwDscPdfD7h84BabPwGwrfTTE5FSGcqn8dcBuBvAVjNrL1z2KIA7zawF/eW4TgD3R1fU19cH9nd7VHJgpZioTJO3hJRn6+FilyQOFbv+PPcLyF+yZCWuvMclesyZKVOm5LrtaO6sPAbw0lv0mER5kmUon8avAzDYPaM1dRGpLjqDTiQRSnaRRCjZRRKhZBdJhJJdJBFKdpFElLWV9IgRI2jdNc+SxdraWhqPlqFOnDiRxk+dOpUZy9sqOk+75ej6ozp4VNONjlseUZ08Oi7RfWOixyy67ui8jagOz5b+RttJs+PG5qVXdpFEKNlFEqFkF0mEkl0kEUp2kUQo2UUSoWQXSYTlqVX+4Bsz+xuAPQMumgzgUNkm8MNU69yqdV6A5lasUs5tlrsPuli/rMn+vRs3a3P31opNgKjWuVXrvADNrVjlmpvexoskQskukohKJ/uqCt8+U61zq9Z5AZpbscoyt4r+zS4i5VPpV3YRKRMlu0giKpLsZnazme00s91m9kgl5pDFzDrNbKuZtZtZW4Xn8qKZHTSzbQMum2Rma81sV+HroHvsVWhuj5tZV+HYtZvZ0grNbaaZvWtm283sEzN7qHB5RY8dmVdZjlvZ/2Y3s5EAPgPwrwD2AdgA4E53317WiWQws04Are5e8RMwzOxfAJwE8Ht3n1+47GkAh939qcIvygZ3/48qmdvjAE5Wehvvwm5FTQO3GQewDMC/oYLHjszrDpThuFXilX0BgN3u3uHuXwP4I4DbKjCPqufu7wM4/J2LbwOwuvD9avQ/WcouY25Vwd273X1T4fsTAL7ZZryix47MqywqkewzAHwx4P/7UF37vTuAv5rZRjNbUenJDGKau3cXvj8AYFolJzOIcBvvcvrONuNVc+yK2f48L31A932L3P0aAD8G8LPC29Wq5P1/g1VT7XRI23iXyyDbjP9dJY9dsduf51WJZO8CMHPA/y8qXFYV3L2r8PUggNdQfVtR93yzg27h68EKz+fvqmkb78G2GUcVHLtKbn9eiWTfAOBSM5ttZqMB/BTA6xWYx/eYWW3hgxOYWS2Am1B9W1G/DuDewvf3AlhTwbl8S7Vs4521zTgqfOwqvv25u5f9H4Cl6P9E/n8APFaJOWTM658AbC78+6TScwPwCvrf1p1F/2cb9wFoBPA2gF0A3gIwqYrm9jKArQC2oD+xmio0t0Xof4u+BUB74d/SSh87Mq+yHDedLiuSCH1AJ5IIJbtIIpTsIolQsoskQskukgglu0gilOwiifhfpuDapYEP/pAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Preference score:\", train_set[i][1])\n",
    "plt.imshow(train_set[i][0].permute(1,2,0), cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa13d1f-5fbe-46e5-883a-7e92f1b2c7b7",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "beb12426-cc72-4222-8698-204cabb661e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "stop",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [304], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mException\u001B[0m: stop"
     ]
    }
   ],
   "source": [
    "raise Exception(\"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "af525249-efcf-4cfb-94ca-8e161a56b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(train_set)):\n",
    "    scores.append(train_set[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c406c9c3-75a4-4d6a-9df4-b9548cb0e4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 1226,\n",
       "         1: 1724,\n",
       "         0: 1163,\n",
       "         5: 335,\n",
       "         3: 764,\n",
       "         7: 82,\n",
       "         4: 496,\n",
       "         6: 179,\n",
       "         8: 27,\n",
       "         9: 4})"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "ae0cca8f-f1aa-45db-9dbd-266c72c3dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score = 9: [562, 2984, 3392, 4864]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fee9f04a-6dbf-4c13-9874-c4c097332e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f37be981-7415-46a9-a6d1-2efd7a047bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference score: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Preference score:\", train_set[i][1])\n",
    "permuted_train_set = train_set[i][0].permute(1,2,0)\n",
    "\n",
    "plt.imshow((permuted_train_set+1)*.5, cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "#i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2aef2a17-72c7-45ba-9c80-4b19e1a8bba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 83.4710,  84.0139,  80.3743,  ..., 103.8327,  92.7517,  66.2770],\n",
       "         [107.6457,  92.3275,  70.3172,  ..., 114.7835, 107.3760, 102.4781],\n",
       "         [ 94.4461,  99.4346,  83.4237,  ..., 119.2529, 109.8161, 103.0797],\n",
       "         ...,\n",
       "         [ 96.7647,  98.9268, 104.6256,  ...,  75.2343,  75.2343,  75.2343],\n",
       "         [ 93.7166,  98.3483, 102.9799,  ...,  73.2267,  73.2267,  73.2267],\n",
       "         [ 86.0207,  93.3292,  98.1281,  ...,  73.0593,  72.2228,  73.0593]],\n",
       "\n",
       "        [[ 83.4710,  84.0139,  80.3743,  ..., 103.8327,  92.7517,  66.2770],\n",
       "         [107.6457,  92.3275,  70.3172,  ..., 114.7835, 107.3760, 102.4781],\n",
       "         [ 94.4461,  99.4346,  83.4237,  ..., 119.2529, 109.8161, 103.0797],\n",
       "         ...,\n",
       "         [ 96.7647,  98.9268, 104.6256,  ...,  75.2343,  75.2343,  75.2343],\n",
       "         [ 93.7166,  98.3483, 102.9799,  ...,  73.2267,  73.2267,  73.2267],\n",
       "         [ 86.0207,  93.3292,  98.1281,  ...,  73.0593,  72.2228,  73.0593]],\n",
       "\n",
       "        [[ 83.4710,  84.0139,  80.3743,  ..., 103.8327,  92.7517,  66.2770],\n",
       "         [107.6457,  92.3275,  70.3172,  ..., 114.7835, 107.3760, 102.4781],\n",
       "         [ 94.4461,  99.4346,  83.4237,  ..., 119.2529, 109.8161, 103.0797],\n",
       "         ...,\n",
       "         [ 96.7647,  98.9268, 104.6256,  ...,  75.2343,  75.2343,  75.2343],\n",
       "         [ 93.7166,  98.3483, 102.9799,  ...,  73.2267,  73.2267,  73.2267],\n",
       "         [ 86.0207,  93.3292,  98.1281,  ...,  73.0593,  72.2228,  73.0593]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_set[0][0]+1)*256/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in5310",
   "language": "python",
   "name": "in5310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
