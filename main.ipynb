{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50887319-cdb6-4904-b104-d27754d7a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the main device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32967635-a522-4798-bfff-9d26a69e115b",
   "metadata": {},
   "source": [
    "# Datapreprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa595a-7664-42a0-b460-f3f9a5e1fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "import litdata\n",
    "import torchvision.transforms as T\n",
    "# Specify data folder\n",
    "datapath = '/projects/ec232/data/'\n",
    "# Define mean and std from ImageNet data\n",
    "in_mean = [0.485,0.456,0.406]\n",
    "in_std = [0.229,0.224,0.225]\n",
    "# Define postprocessing / transform of data modalities\n",
    "postprocess = ( # Create tuple for image and class ...\n",
    "T.Compose([ # Handles processing of the .jpg image\n",
    "T.ToTensor() , # Convert from PIL image to torch . Tensor\n",
    "T.Normalize( in_mean , in_std ) , # Normalize image to correct mean /std.\n",
    "]),\n",
    "T.ToTensor() , # Convert . scores .npy file to tensor .\n",
    ")\n",
    "# Load training data\n",
    "data = litdata . LITDataset (\n",
    "'CarRecs',\n",
    "datapath ,\n",
    "override_extensions =[ # Sets the order of the modalities :\n",
    "'jpg', # ... load image first ,\n",
    "'scores .npy' # ... load scores second .\n",
    "] ,\n",
    ").map_tuple(*postprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176962c-4fda-41ff-bed2-48340a8552dd",
   "metadata": {},
   "source": [
    "# Hyperparameters and Training Loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809c8ca-b9aa-480f-b729-9ed57ab7c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the latent dimension. You can for example use z_dim=2\n",
    "z_dim = 2\n",
    "\n",
    "# Initialize the VAE\n",
    "model = VAE(z_dim, n_channels=1).to(device)\n",
    "\n",
    "# Choose the training parameters. Feel free to change them.\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = Adam(model.parameters(), lr = lr)\n",
    "\n",
    "# Train for a few epochs\n",
    "model.train()\n",
    "with traindata.shufflecontext(): #Fetched from the project description\n",
    "    for epoch in range(epochs):\n",
    "        train_bar = tqdm(iterable=train_loader)\n",
    "        for i, (x, c) in enumerate(train_bar):\n",
    "            \n",
    "            x = x.to(device)\n",
    "            # Get x_hat, mean, and logvar from the VAE model\n",
    "            x_hat, mean, logvar = model(x)\n",
    "    \n",
    "            # Get vae loss\n",
    "            loss = vae_loss(x, x_hat, mean, logvar)\n",
    "    \n",
    "            # Update model parameters based on loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_bar.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            train_bar.set_postfix(loss = loss.item() / len(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "in5310",
   "language": "python",
   "name": "in5310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
